{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, ConcatDataset, SubsetRandomSampler, random_split\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import transformers\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot function for plotting accuracies over epochs\n",
    "\n",
    "def plot(val_accs, train_accs, save_folder=\"plots\"):\n",
    "    # Create the save folder if it doesn't exist\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    # Plot the accuracy scores for each epoch\n",
    "    epochs = np.arange(1, len(train_accs) + 1)\n",
    "\n",
    "    # Plot validation accuracy\n",
    "    if len(val_accs) > 0:\n",
    "        ax.plot(epochs, val_accs, label='Validation')\n",
    "\n",
    "    # Plot training accuracy\n",
    "    ax.plot(epochs, train_accs, label='Training', linestyle='--')\n",
    "\n",
    "    ax.set_title('Accuracy Scores')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.legend()\n",
    "\n",
    "    # Adjust layout and save the plot\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(save_folder, \"accuracy_plot.png\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and augment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./dataset\"\n",
    "\n",
    "input_shape = (3, 224, 224)  # C,W,H\n",
    "\n",
    "transformations = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((input_shape[1], input_shape[2])),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.RandomRotation(40),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_data = ImageFolder(os.path.join(data_dir, 'train'), transform=transformations)\n",
    "val_data = ImageFolder(os.path.join(data_dir, 'val'), transform=transformations)\n",
    "test_data = ImageFolder(os.path.join(data_dir, 'test'), transform=transformations)\n",
    "\n",
    "dataset = ConcatDataset([train_data, val_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation methods to calculate accuracy of a model\n",
    "class AverageMeter(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.cnt = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.sum += val * n\n",
    "        self.cnt += n\n",
    "        self.avg = self.sum / self.cnt\n",
    "\n",
    "\n",
    "def accuracy(logits, labels):\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    return torch.sum(preds == labels) / len(labels)\n",
    "\n",
    "\n",
    "def eval_fn(model, loader, device):\n",
    "\n",
    "    score = AverageMeter()\n",
    "    model.eval()\n",
    "\n",
    "    t = tqdm(loader)\n",
    "    with torch.no_grad():  # no gradient needed\n",
    "        for images, labels in t:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            acc = accuracy(outputs, labels)\n",
    "            score.update(acc.item(), images.size(0))\n",
    "\n",
    "            t.set_description('(=> Test) Score: {:.4f}'.format(score.avg))\n",
    "\n",
    "    return score.avg\n",
    "\n",
    "# train function\n",
    "def train_fn(model, optimizer, criterion, loader, device):\n",
    "\n",
    "    time_begin = time.time()\n",
    "    score = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    model.train()\n",
    "    time_train = 0\n",
    "\n",
    "    t = tqdm(loader)\n",
    "    for images, labels in t:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = accuracy(logits, labels)\n",
    "        n = images.size(0)\n",
    "        losses.update(loss.item(), n)\n",
    "        score.update(acc.item(), n)\n",
    "\n",
    "        t.set_description('(=> Training) Loss: {:.4f}'.format(losses.avg))\n",
    "\n",
    "    time_train += time.time() - time_begin\n",
    "    print('training time: ' + str(time_train))\n",
    "    return score.avg, losses.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomViTForImageClassification(nn.Module):\n",
    "    # initialize small Visual Transformer model from pretrained ImageNet dataset for 224x224 images\n",
    "    # then all layers are frozen except the new classifier used for the finetuning to our custom dataset\n",
    "    def __init__(self, num_classes, pretrained_model_name='WinKawaks/vit-small-patch16-224'):\n",
    "        super(CustomViTForImageClassification, self).__init__()\n",
    "        # Load pre-trained ViT model\n",
    "        self.vit_model = transformers.ViTForImageClassification.from_pretrained(pretrained_model_name)\n",
    "        for param in self.vit_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.vit_model.classifier = nn.Linear(self.vit_model.config.hidden_size, num_classes)\n",
    "\n",
    "    # change forward method to only return class probabilities as we don't need the labels in the output\n",
    "    def forward(self, pixel_values, labels=None):\n",
    "        outputs = self.vit_model(pixel_values, labels=labels)\n",
    "        return outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_classes = 10 in our dataset\n",
    "model = CustomViTForImageClassification(10).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.007, momentum=0.7)\n",
    "#scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=60)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max = 100)\n",
    "\n",
    "param_count = sum(p.numel() for p in model.parameters())\n",
    "print(F\"Total parameters: {param_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for training\n",
    "\n",
    "train_criterion=torch.nn.CrossEntropyLoss().to(device)\n",
    "num_epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "# if len(split_ratio) == 3 we randomly split the dataset into train/val/test\n",
    "# if it is 2 we split into train/test and don't do validation in training\n",
    "split_ratio = [0.6, 0.2, 0.2]\n",
    "\n",
    "if len(split_ratio) == 3:\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, split_ratio)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "if len(split_ratio) == 2:\n",
    "    train_dataset, test_dataset = random_split(dataset, split_ratio)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accs = []\n",
    "train_accs = []\n",
    "train_losss = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('#' * 50)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, lr: {scheduler.get_last_lr()}\")\n",
    "\n",
    "    train_score, train_loss = train_fn(model, optimizer, train_criterion, train_loader, device)\n",
    "    print('Train accuracy: %f', train_score)\n",
    "\n",
    "    if len(split_ratio) > 2:\n",
    "        test_score = eval_fn(model, val_loader, device)\n",
    "        print('Validation accuracy: %f', test_score)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    val_accs.append(test_score)\n",
    "    train_accs.append(train_score)\n",
    "    train_losss.append(train_loss)\n",
    "\n",
    "print('--------------------------------')\n",
    "# Compare validation and train accuracy to find if we overfit\n",
    "plot(val_accs, train_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_loader = DataLoader(dataset=ConcatDataset([train_data, val_data, test_data]), batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Find accuracy on test set, important to not use it anywhere in training\n",
    "score = eval_fn(model, test_loader, device)\n",
    "print('Avg accuracy test dataset:', str(score*100) + '%')\n",
    "\n",
    "# For comparison check accuracy on full dataset which should be higher as we trained on most of the data\n",
    "score = eval_fn(model, full_loader, device)\n",
    "print('Avg accuracy full dataset:', str(score*100) + '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
